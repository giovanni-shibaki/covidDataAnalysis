{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rio Grande do Sul COVID cases Data Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SYh8dmzZwFSC"
   },
   "outputs": [],
   "source": [
    "import dateutil.utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import re\n",
    "import scipy\n",
    "from unidecode import unidecode\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Merging all data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S8huGrm9w7I8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ÿid           dataNotificacao        dataInicioSintomas  \\\n",
      "0  HE8B8WiBpk  2020-08-25T03:00:37.280Z  2020-08-24T03:00:00.000Z   \n",
      "1  IfUV4kqF1I  2020-08-17T03:00:48.914Z  2020-08-03T03:00:00.000Z   \n",
      "2  auCqY2SQ4w  2020-06-26T17:37:33.237Z  2020-06-10T03:00:00.000Z   \n",
      "3  R8MGrEmw1z  2020-06-26T03:00:00.000Z  2020-06-26T03:00:00.000Z   \n",
      "4  w6ClV1iTLg  2020-08-21T03:00:51.066Z  2020-08-11T03:00:00.000Z   \n",
      "\n",
      "  dataNascimento       sintomas profissionalSaude  \\\n",
      "0      undefined         Outros               Não   \n",
      "1      undefined         Outros               Não   \n",
      "2      undefined         Outros               Não   \n",
      "3      undefined  Tosse, Outros               Sim   \n",
      "4      undefined         Outros               Não   \n",
      "\n",
      "                                                 cbo  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  5151 - Outro tipo de agente de saúde ou visita...   \n",
      "4                                                NaN   \n",
      "\n",
      "                    condicoes estadoTeste                 dataTeste  ...  \\\n",
      "0                         NaN   Concluído  2020-08-24T03:00:00.000Z  ...   \n",
      "1                         NaN   Concluído  2020-08-17T03:00:00.000Z  ...   \n",
      "2                         NaN   Concluído  2020-06-26T03:00:00.000Z  ...   \n",
      "3                         NaN   Concluído  2020-06-26T03:00:00.000Z  ...   \n",
      "4  Doenças cardíacas crônicas   Concluído  2020-08-11T03:00:00.000Z  ...   \n",
      "\n",
      "   estadoNotificacao estadoNotificacaoIBGE municipioNotificacao  \\\n",
      "0     SANTA CATARINA                  42.0        Florianópolis   \n",
      "1  RIO GRANDE DO SUL                  43.0          Barra Funda   \n",
      "2  RIO GRANDE DO SUL                  43.0              Canguçu   \n",
      "3  RIO GRANDE DO SUL                  43.0             Alvorada   \n",
      "4  RIO GRANDE DO SUL                  43.0         São Leopoldo   \n",
      "\n",
      "  municipioNotificacaoIBGE   excluido   validado idade  \\\n",
      "0                4205407.0  undefined  undefined  40.0   \n",
      "1                4301958.0  undefined  undefined  66.0   \n",
      "2                4304507.0  undefined  undefined  52.0   \n",
      "3                4300604.0  undefined  undefined  33.0   \n",
      "4                4318705.0  undefined  undefined  56.0   \n",
      "\n",
      "           dataEncerramento              evolucaoCaso  \\\n",
      "0                       NaN                       NaN   \n",
      "1                       NaN                       NaN   \n",
      "2  2020-06-26T03:00:00.000Z                      Cura   \n",
      "3  2020-07-01T03:00:00.000Z  Em tratamento domiciliar   \n",
      "4  2020-08-21T03:00:00.000Z                      Cura   \n",
      "\n",
      "                 classificacaoFinal  \n",
      "0                               NaN  \n",
      "1           Confirmado Laboratorial  \n",
      "2  Síndrome Gripal Não Especificada  \n",
      "3           Confirmado Laboratorial  \n",
      "4                               NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "d1 = pd.read_csv(\"../db/dados-rs-1.csv\", delimiter=\";\", on_bad_lines='skip', encoding='latin1', low_memory=True)\n",
    "d2 = pd.read_csv(\"../db/dados-rs-2.csv\", delimiter=\";\", on_bad_lines='skip', encoding='latin1', low_memory=True)\n",
    "d3 = pd.read_csv(\"../db/dados-rs-3.csv\", delimiter=\";\", on_bad_lines='skip', encoding='latin1', low_memory=True)\n",
    "d4 = pd.read_csv(\"../db/dados-rs-4.csv\", delimiter=\";\", on_bad_lines='skip', encoding='latin1', low_memory=True)\n",
    "d5 = pd.read_csv(\"../db/dados-rs-5.csv\", delimiter=\";\", on_bad_lines='skip', encoding='latin1', low_memory=True)\n",
    "d6 = pd.read_csv(\"../db/dados-rs-6.csv\", delimiter=\";\", on_bad_lines='skip', encoding='latin1', low_memory=True)\n",
    "\n",
    "df = pd.concat([d1, d2, d3, d4, d5, d6])\n",
    "df.to_csv('dados-rs.csv', index=False)\n",
    "\n",
    "# CBO - Classificação Brasileira de Ocupações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv(\"dados-rs.csv\", delimiter=\",\", on_bad_lines='skip', encoding='utf-8', low_memory=True)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UZinxgK0xOKB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Some of the columns have values different from null or NaN\n",
    "# but they are defined as 'undefined'\n",
    "\n",
    "# After the analysis, the columns that must be droped are:\n",
    "#   CBO\n",
    "#   PaisOrigem\n",
    "#   estado\n",
    "#   estadoIBGE\n",
    "#   origem\n",
    "#   excluido\n",
    "#   validado\n",
    "#   dataNascimento\n",
    "\n",
    "# Dropping columns that we deem to be unserviceable to our data analysis\n",
    "df.drop(columns=[\"cbo\", \"paisOrigem\", \"estado\", \"estadoIBGE\", \"origem\", \"excluido\", \"validado\", \"dataNascimento\"],\n",
    "        inplace=True)\n",
    "\n",
    "# Some of the values are defined as 'undefined', which are not\n",
    "# classified as null or NaN for the pandas function\n",
    "# Then, we are going to change this value to 'null'\n",
    "df.sexo.replace(\"Indefinido\", \"null\")\n",
    "\n",
    "# Changing the data type of some columns to datetime\n",
    "df.dataNotificacao = pd.to_datetime(df.dataNotificacao, errors='coerce')\n",
    "df.dataTeste = pd.to_datetime(df.dataTeste, errors='coerce')\n",
    "df.dataEncerramento = pd.to_datetime(df.dataEncerramento, errors='coerce')\n",
    "df.dataInicioSintomas = pd.to_datetime(df.dataInicioSintomas, errors='coerce')\n",
    "\n",
    "# Some lines (44510 [pd.isnull(df.sintomas).sum()]) have no symptoms described (== 'null')\n",
    "# then, we are going to drop those lines\n",
    "df = df[pd.notnull(df.sintomas)]\n",
    "\n",
    "# There are some inconsistencies into de age date (i.e. ages up to 320)\n",
    "# Since the population in RS with +100 is less than 0.0009% of the total population\n",
    "# we are going to drop those lines with 100+ years\n",
    "df = df[df.idade <= 100]\n",
    "\n",
    "# Replacing variations of 'Dispneia' to only the correct spelling\n",
    "df.sintomas.replace(regex=['Dispineia', 'Dispinéia', 'Dispnéia', 'Dificuldade De Respirar'], value='Dispneia',\n",
    "                    inplace=True)\n",
    "\n",
    "# Replacing variants of 'Assintomático'\n",
    "df.sintomas.replace(regex=['Outros: Paciente assintomático'], value='Assintomático', inplace=True)\n",
    "\n",
    "# Replacing variants of 'Dor de Garganta'\n",
    "df.sintomas.replace(regex=['Dor De Garganta'], value='Dor de Garganta', inplace=True)\n",
    "\n",
    "# Listing the symptoms\n",
    "sintomas = []\n",
    "\n",
    "# Splitting symptom column values into a tuple of symptoms\n",
    "for i in df.sintomas:\n",
    "    sintoma = re.split(\",|, \", str(i))\n",
    "    for j in sintoma:\n",
    "        if j.strip() not in sintomas and j.strip() != '':\n",
    "            sintomas.append(j.strip())\n",
    "\n",
    "# Create the new columns to the symptoms variants\n",
    "aux = 4\n",
    "for i in sintomas:\n",
    "    df.insert(aux, i, 'False')\n",
    "    aux += 1\n",
    "\n",
    "# For each symptom list, modify the target column for each symptom\n",
    "for index, row in df.iterrows():\n",
    "    for sim in sintomas:\n",
    "        if sim in row['sintomas']:\n",
    "            df.at[index, sim] = 'True'\n",
    "\n",
    "# Saving the dataset without the selected columns\n",
    "df.to_csv('../db/dados-rs-clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the clean dataframe\n",
    "df = pd.read_csv(\"../db/dados-rs-clean.csv\", delimiter=\",\", on_bad_lines='skip', encoding='utf-8', low_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dados-rs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-f686425646bb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'dados-rs.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \"\"\"\n\u001B[0;32m--> 222\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 702\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'dados-rs.csv'"
     ]
    }
   ],
   "source": [
    "# Sorting DataFrame by dataNotificacao\n",
    "df.sort_values(by=['dataNotificacao'], inplace=True)\n",
    "print(df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving sorted dataframe into a new .csv\n",
    "df.to_csv('../db/dados-rs-clean-sorted.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the clean and sorted dataframe\n",
    "df = pd.read_csv(\"../db/dados-rs-clean-sorted.csv\", delimiter=\",\", on_bad_lines='skip', encoding='utf-8',\n",
    "                 low_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converting date columns to Date (yyyy-MM-dd)\n",
    "df.dataNotificacao = pd.to_datetime(df.dataNotificacao, errors='coerce').dt.date\n",
    "df.dataTeste = pd.to_datetime(df.dataTeste, errors='coerce').dt.date\n",
    "df.dataEncerramento = pd.to_datetime(df.dataEncerramento, errors='coerce').dt.date\n",
    "df.dataInicioSintomas = pd.to_datetime(df.dataInicioSintomas, errors='coerce').dt.date"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dropping lines without 'dataNotificacao'\n",
    "df = df[pd.notnull(df.dataNotificacao)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating new columns to describe week and year number\n",
    "df.insert(31, 'WeekNumber', 'null')\n",
    "df.insert(32, 'YearNumber', 'null')\n",
    "\n",
    "df['WeekNumber'] = df.dataNotificacao.apply(lambda x: x.isocalendar()[1])\n",
    "df['YearNumber'] = df.dataNotificacao.apply(lambda x: x.isocalendar()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Data Analysis\n",
    "## 26. Has there been a significant surge in the number of COVID-19 cases in dates close to public (national and state) holidays?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generateHollidayPlot(date1, date2, title):\n",
    "    df1 = df.loc[(df.dataNotificacao >= date1) & (df.dataNotificacao <= date2)]\n",
    "    fig = sns.histplot(df1.dataNotificacao, kde=True)\n",
    "    fig.set_title(title)\n",
    "    for item in fig.get_xticklabels():\n",
    "        item.set_rotation(45)\n",
    "        item.set_horizontalalignment = 'right'\n",
    "    plt.savefig(f\"../plots/{title.strip().lower().replace(' ', '_')}{date1.year}.png\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Carnival (24/02) (26/02/2020)\n",
    "generateHollidayPlot(date(2020, 2, 10), date(2020, 3, 18), 'Carnaval')\n",
    "\n",
    "# Paixão de Cristo (10/04/2020)\n",
    "generateHollidayPlot(date(2020, 3, 27), date(2020, 5, 1), 'Paixao de Cristo')\n",
    "\n",
    "# Tiradentes (21/04/2020)\n",
    "generateHollidayPlot(date(2020, 4, 7), date(2020, 5, 12), 'Tiradentes')\n",
    "\n",
    "# Dia Mundial do Trabalho (01/05/2020)\n",
    "generateHollidayPlot(date(2020, 4, 17), date(2020, 5, 22), 'Dia do Trabalho')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Courpus Christi (11/06/2020)\n",
    "generateHollidayPlot(date(2020, 5, 28), date(2020, 7, 2), 'Corpus Christi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Independencia do Brasil (07/09/2020)\n",
    "generateHollidayPlot(date(2020, 8, 24), date(2020, 9, 28), 'Independencia do Brasil')\n",
    "\n",
    "# Dia do Gaucho / Rev Farroupilha (20/09/2020)\n",
    "generateHollidayPlot(date(2020, 9, 6), date(2020, 10, 11), 'Dia do Gaucho')\n",
    "\n",
    "# Nossa Senhora Aparecida (12/10/2020)\n",
    "generateHollidayPlot(date(2020, 9, 28), date(2020, 11, 2), 'Nossa Senhora Aparecida')\n",
    "\n",
    "# Dia do Servidor Publico (28/10/2020)\n",
    "generateHollidayPlot(date(2020, 10, 14), date(2020, 11, 18), 'Dia do servidor publico')\n",
    "\n",
    "# Dia dos Finados (02/11/2020)\n",
    "generateHollidayPlot(date(2020, 10, 19), date(2020, 11, 23), 'Finados')\n",
    "\n",
    "# Proclamacao da republica (15/11/2020)\n",
    "generateHollidayPlot(date(2020, 11, 1), date(2020, 12, 6), 'Proclamacao da Republica')\n",
    "\n",
    "# Natal (25/12/2020)\n",
    "generateHollidayPlot(date(2020, 12, 11), date(2021, 1, 15), 'Natal')\n",
    "\n",
    "# Ano novo (01/01/2021)\n",
    "generateHollidayPlot(date(2020, 12, 17), date(2021, 1, 22), 'Ano novo')\n",
    "\n",
    "# Carnaval (15/02/2021)\n",
    "generateHollidayPlot(date(2021, 2, 1), date(2021, 3, 10), 'Carnaval')\n",
    "\n",
    "# Paixao de Cristo (02/04/2021)\n",
    "generateHollidayPlot(date(2021, 3, 19), date(2021, 4, 23), 'Paixao de Cristo')\n",
    "\n",
    "# Tirandentes (21/04/2021)\n",
    "generateHollidayPlot(date(2021, 4, 7), date(2021, 5, 5), 'Tiradentes')\n",
    "\n",
    "# Dia Mundial do Trabalho (21/04/2021)\n",
    "generateHollidayPlot(date(2021, 4, 17), date(2021, 5, 22), 'Dia do Trabalho')\n",
    "\n",
    "# Corpus Christi (03/06/2021)\n",
    "generateHollidayPlot(date(2021, 5, 20), date(2021, 6, 24), 'Corpus Christi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = df.loc[(df.dataNotificacao >= date(2020, 5, 28)) & (df.dataNotificacao <= date(2020, 11, 14))]\n",
    "#df2 = df.loc[(df.dataNotificacao >= date(2020, 4, 24)) & (df.dataNotificacao <= date(2020, 5, 29))]\n",
    "\n",
    "df2 = df1.groupby(df['WeekNumber'])['ÿid'].count()\n",
    "df2.diff()\n",
    "df2.plot(kind='line', figsize=(10, 5), legend=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# General graph per year\n",
    "\n",
    "def generateYearCasesGraphGroupByWeeks(yearNumber):\n",
    "    dfA = df.loc[df.YearNumber == yearNumber]\n",
    "    dfB = dfA.groupby(df['WeekNumber'])['ÿid'].count()\n",
    "    dfB.diff()\n",
    "    dfB.plot(kind='line', figsize=(10, 5), legend=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of registered cases in 2020"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generateYearCasesGraphGroupByWeeks(2020)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of registered cases in 2021"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generateYearCasesGraphGroupByWeeks(2021)\n",
    "\n",
    "# Gráfico da diferença\n",
    "# Colocar um ponto colorido em todo feriado\n",
    "# +2 pontos nas duas proximas semanas depois do feriado, para ver se\n",
    "# são de subida\n",
    "\n",
    "# Calcular a média móvel 2 semans antes e 2 semanas depois e plotar em\n",
    "# cima desse gráfico"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate the graph with the full dataframe (2020 + 2021)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = df.loc[df.YearNumber == 2020].copy()\n",
    "df2 = df.loc[df.YearNumber == 2021].copy()\n",
    "df2['WeekNumber'] = df2.WeekNumber.apply(lambda x: x + 53)\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df2.tail(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merging the 2020 dataframe with the 2021 dataframe\n",
    "df1 = pd.concat([df1, df2])\n",
    "df1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the full dataframe graph\n",
    "df2 = df1.groupby(df1['WeekNumber'])['ÿid'].count()\n",
    "df2 = df2.diff()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 14))\n",
    "plot = sns.lineplot(\n",
    "    data=df2\n",
    ")\n",
    "plot.set(xlabel='Weeks', ylabel='New Cases Per Week', title='Total cases per week from January 2020 to June 2021')\n",
    "\n",
    "feriados = {\n",
    "    'Feriado': [\"1. Carnaval 20\", \"2. Paixao Cristo 20\", \"3. Tiradentes 20\", \"4. Dia Trabalho 20\",\n",
    "                \"5. Corpus Christi 20\", \"6. Independencia 20\",\n",
    "                \"7. Dia Gaucho 20\", \"8. Dia Crianca 20\", \"9. ServidorPublico20\", \"10. Finados20\",\n",
    "                \"11. Proclamacao Republica 20\", \"12. Natal 20\",\n",
    "                \"13. Ano Novo 20\", \"14. Carnaval 21\", \"15. Paixao Cristo 21\", \"16. Tiradentes 21\",\n",
    "                \"17. Dia Trabalho 21\", \"18. Corpus Christi 21\"],\n",
    "    'Data': [date(2020, 2, 25).isocalendar()[1], date(2020, 4, 10).isocalendar()[1], date(2020, 4, 21).isocalendar()[1],\n",
    "             date(2020, 5, 1).isocalendar()[1], date(2020, 6, 11).isocalendar()[1], date(2020, 9, 7).isocalendar()[1],\n",
    "             date(2020, 9, 20).isocalendar()[1], date(2020, 10, 12).isocalendar()[1],\n",
    "             date(2020, 10, 28).isocalendar()[1], date(2020, 11, 2).isocalendar()[1],\n",
    "             date(2020, 11, 15).isocalendar()[1], date(2020, 12, 25).isocalendar()[1],\n",
    "             date(2020, 12, 31).isocalendar()[1], 53 + date(2021, 2, 16).isocalendar()[1],\n",
    "             53 + date(2021, 4, 2).isocalendar()[1],\n",
    "             53 + date(2021, 4, 21).isocalendar()[1], 53 + date(2021, 5, 1).isocalendar()[1],\n",
    "             53 + date(2021, 6, 11).isocalendar()[1]\n",
    "             ]\n",
    "}\n",
    "\n",
    "dff = pd.DataFrame(feriados)\n",
    "\n",
    "sns.scatterplot(x=dff['Data'], y=0, s=0, hue=dff['Feriado'], palette='Paired')\n",
    "sns.color_palette(\"Paired\", 1)\n",
    "\n",
    "for i, j in df2.items():\n",
    "    ax.scatter(x=i, y=df2[i], s=10, c='#1F77B4')\n",
    "\n",
    "\n",
    "# Fuction to add the Holliday points to the scatter plot\n",
    "def addHolidayPoints(data):\n",
    "    ax.scatter(x=data - 1, y=df2[data - 1], s=50, c='red')\n",
    "    ax.annotate('', xy=(data - 1, df2[data - 1]))\n",
    "\n",
    "\n",
    "# Adding the points\n",
    "for value in feriados['Data']:\n",
    "    addHolidayPoints(value)\n",
    "\n",
    "plt.savefig(f\"../plots/teste.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 31. What are the most common symptoms by age group? Is there a pattern?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the dataframe\n",
    "df = pd.read_csv(\"../db/dados-rs-clean-sorted.csv\", delimiter=\",\", on_bad_lines='skip', encoding='utf-8',\n",
    "                 low_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate the population by age intervals\n",
    "# Possibilities:\n",
    "# 1. Using the same age classes as the IBGE's age pyramid (INSERT REFERENCE)\n",
    "# 5 to 5 years\n",
    "# = 19 classes\n",
    "\n",
    "df_per_age = []\n",
    "\n",
    "for i in range(19):\n",
    "    df_per_age[i] = df.loc[df.idade >= i * 5 & df.idade < i * 5 + 5]\n",
    "\n",
    "cases_with_symptoms_per_age = []\n",
    "\n",
    "# vector of dictionaries (each one with all possible symptoms)\n",
    "for i in range(19):\n",
    "    cases_with_symptoms_per_age.append({\n",
    "        \"Outros\": 0,\n",
    "        \"Tosse\": 0,\n",
    "        \"Dor de Garganta\": 0,\n",
    "        \"Febre\": 0,\n",
    "        \"Dispneia\": 0,\n",
    "        \"Assintomático\": 0,\n",
    "        \"Dor de Cabeça\": 0,\n",
    "        \"Coriza\": 0,\n",
    "        \"Distúrbios Gustativos\": 0,\n",
    "        \"Distúrbios Olfativos\": 0,\n",
    "    })\n",
    "\n",
    "# filling up\n",
    "\n",
    "# each age group within df_per_age\n",
    "for i in range(19):\n",
    "    total = df.loc[d]\n",
    "\n",
    "    # each line in df_per_age\n",
    "    for index, row in df_per_age[i].iterrows():\n",
    "        # each symptom in the given line of the dictionary array\n",
    "        for key, value in cases_with_symptoms_per_age[i].items():\n",
    "            if row[key] == 'True':\n",
    "                cases_with_symptoms_per_age[i][key] += 1\n",
    "\n",
    "# 1: Using the square rule\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 34. What is the most used COVID test in the state? Proportionally, what is the percentage of positive results? How about negative ones?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the dataframe\n",
    "df = pd.read_csv(\"../db/dados-rs-clean-sorted.csv\", delimiter=\",\", on_bad_lines='skip', encoding='utf-8',\n",
    "                 low_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}